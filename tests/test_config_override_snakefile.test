#!/usr/bin/env bash

## Test: override config for snakefile
## assumes you already know the logfile and output overrides work
echo 1..1

TESTNAME="test_config_override_snakefile"
TESTDESCRIPTION="override --snakefile from config"
CONFIGFILE="tests/examples/test_interface/input/config.defaults.yaml"
OUTPUTDIR="tests/examples/test_interface/config_override_snakefile/output"
EXPECTEDDIR="tests/examples/test_interface/config_override_snakefile/expected"
SNAKEMAKE_UNIT_TESTS="./snakemake_unit_tests.out"

## override parameters
SNAKEFILE="tests/examples/test_interface/input/choice1/Snakefile"
SNAKEMAKE_LOG="tests/examples/test_interface/input/choice1/run2.log"

## just in case, delete existing output from previously failed tests
rm -Rf "$OUTPUTDIR"

## run test, dumping output into appropriate directory
"$SNAKEMAKE_UNIT_TESTS" -c "$CONFIGFILE" -o "$OUTPUTDIR" -s "$SNAKEFILE" -l "$SNAKEMAKE_LOG" > /dev/null 2>&1
if [[ "$?" != "0" ]] ; then
    echo "not ok - $TESTDESCRIPTION primary run failed"
    exit 0
fi

## compare expected to observed output, ignoring pytest infrastructure
tests/compare_directories.bash "$EXPECTEDDIR" "$OUTPUTDIR" "$TESTDESCRIPTION"
if [[ "$?" != "0" ]] ; then
    exit 0
fi

## since this is expected pass, enforce pytest functionality as a proxy for pytest configuration
pytest "$OUTPUTDIR/unit" > /dev/null 2>&1

if [[ "$?" != "0" ]] ; then
    echo "not ok - $TESTDESCRIPTION downstream pytest failed"
    exit 0
fi

## remove output
rm -Rf "$OUTPUTDIR"

## report success
echo "ok - $TESTDESCRIPTION"
